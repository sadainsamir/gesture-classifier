# ğŸ¤– Gesture Classifier (MediaPipe + ML)

Classifies body gestures using MediaPipe Holistic landmarks and a trained ML model.  
Built for real-time gesture recognition using pose and hand landmarks.

---

## ğŸ“¦ Project Files

gesture-classifier/ â”œâ”€â”€ gesture_app.py # Main real-time app â”œâ”€â”€ ai body language.ipynb # Notebook for training & testing â”œâ”€â”€ pose_classifier.h5 # Trained Keras model â”œâ”€â”€ coords.csv # Extracted features (landmarks + labels) â”œâ”€â”€ requirements.txt # Dependencies â”œâ”€â”€ .gitignore # Ignored files config


---

## âš™ï¸ Setup & Run

```bash
# Create and activate virtual environment (optional)
python -m venv venv
venv\Scripts\activate      # For Windows
source venv/bin/activate  # For macOS/Linux

# Install dependencies
pip install -r requirements.txt

# Run the app
python gesture_app.py
```

# ğŸ§  Models & Tools
MediaPipe Holistic â€“ full-body landmark detection

TensorFlow / Keras â€“ for model training & classification

Jupyter Notebook â€“ for training and exporting features to CSV

# ğŸ“ Notes
.mp4, .venv/, and .ipynb_checkpoints/ are excluded via .gitignore

coords.csv is large (~81MB) â€” consider using Git LFS if pushing to GitHub
